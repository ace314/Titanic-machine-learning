# Titanic-machine-learning
This jupyter notebook includes my thinking process for the famous Kaggle competition about Titanic data set: https://www.kaggle.com/competitions/titanic/overview

There are detailed step-by-step descriptions including feature engineering and model building.

## Result for the common classifiers in scikit-learn
The final results for different classifiers:

| Model | Accuracy |
| --- | --- |
| Logistic regression (LR) | 0.734450 |
| Linear discriminant analysis (LDA) | 0.755981 |
| K-th nearest neighbors (KNN) | 0.765550 |
| Decision tree (CART) | 0.705742 |
| Naive Bayes (NB) | 0.751196 |
| Support vector machine (SVM) | 0.760766 |
 <br />
 <br />
 
![download](https://github.com/ace314/Titanic-machine-learning/assets/26135571/70c556e6-fd6f-4806-bb1f-ad835fdc6c47)
