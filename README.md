# Titanic-machine-learning
This jupyter notebook includes my thinking process for the famous Kaggle competition about Titanic data set: https://www.kaggle.com/competitions/titanic/overview

There are detailed step-by-step descriptions including feature engineering and model building.

## Result for the common classifiers in scikit-learn
The final results using test train split with test size = 0.3:

| Model | Accuracy (std) |
| --- | --- |
| Logistic regression (LR) | 0.972734 (0.020390) |
| Linear discriminant analysis (LDA) | 0.963159 (0.020246) |
| K-th nearest neighbors (KNN) | 0.897389 (0.047408) |
| Decision tree (CART) | 0.990348 (0.010684) |
| Naive Bayes (NB) | 0.837916 (0.042133) |
| Support vector machine (SVM) | 0.976037 (0.020410) |
 <br />
 <br />
 
![download](https://github.com/ace314/Titanic-machine-learning/assets/26135571/70c556e6-fd6f-4806-bb1f-ad835fdc6c47)
